{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27531ed1-7d93-4a69-bc17-5fa729ce4bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV exists: True\n",
      "HF_HOME: /scratch/qin.yife/Generative_Project/.cache/huggingface\n",
      "device: cpu | torch: 2.9.0+cpu | python: 3.12.4 | Linux-5.14.0-362.13.1.el9_3.x86_64-x86_64-with-glibc2.34\n",
      "OUT_DIR: /scratch/qin.yife/Generative_Project/outputs/m2\n",
      "LOG_CSV: /scratch/qin.yife/Generative_Project/metrics/m2_runs.csv\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os, sys, platform, torch\n",
    "\n",
    "PROJECT   = Path(\"/scratch/qin.yife/Generative_Project\")\n",
    "CSV_CLEAN = PROJECT/\"data\"/\"processed\"/\"pairs.clean.csv\"\n",
    "HF_HOME   = PROJECT/\".cache\"/\"huggingface\"\n",
    "OUT_DIR   = PROJECT/\"outputs\"/\"m2\"; OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_CSV   = PROJECT/\"metrics\"/\"m2_runs.csv\"; LOG_CSV.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "os.environ[\"HF_HOME\"] = str(HF_HOME)\n",
    "os.environ[\"HF_HUB_ENABLE_HF_TRANSFER\"] = \"0\"\n",
    "print(\"CSV exists:\", CSV_CLEAN.exists())\n",
    "print(\"HF_HOME:\", os.environ[\"HF_HOME\"])\n",
    "print(\"device:\", \"cuda\" if torch.cuda.is_available() else \"cpu\", \"| torch:\", torch.__version__, \"| python:\", sys.version.split()[0], \"|\", platform.platform())\n",
    "print(\"OUT_DIR:\", OUT_DIR)\n",
    "print(\"LOG_CSV:\", LOG_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96a71daf-cf35-4d7a-8c05-fdb8deb02372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved eval prompts -> /scratch/qin.yife/Generative_Project/outputs/m2/eval_prompts.txt\n",
      "01. Two gray dogs run near the water on a manicured lawn in the fall .\n",
      "02. Man in black wetsuit on his surfboard riding a blue wave with the beach and onlookers in the background .\n",
      "03. Many people are clustered closely together , and several of them have alcohol .\n",
      "04. A man in a suit stands next to a white carriage pulled by two white horses while a bride sits inside .\n",
      "05. A man in a white uniform rides a motocross bike down a forest trail .\n",
      "06. A band performs a song with a saxophone , guitars , base , drums and a keyboard .\n",
      "07. A low angled shot of skateboarder in midair while doing a trick , with the blue sky and white clouds in the background .\n",
      "08. Long-necked , flying white bird grazes water with black legs .\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "PROJECT    = Path(\"/scratch/qin.yife/Generative_Project\")\n",
    "CSV_CLEAN  = PROJECT / \"data\" / \"processed\" / \"pairs.clean.csv\"\n",
    "OUT_DIR    = PROJECT / \"outputs\" / \"m2\"\n",
    "PROMPT_TXT = OUT_DIR / \"eval_prompts.txt\"\n",
    "\n",
    "# Load captions\n",
    "df = pd.read_csv(CSV_CLEAN)\n",
    "df[\"caption\"] = df[\"caption\"].astype(str).str.strip()\n",
    "\n",
    "# Basic filtering: non-empty, reasonable length\n",
    "df = df[(df[\"caption\"].str.len() >= 16) & (df[\"caption\"].str.len() <= 120)].drop_duplicates(subset=[\"caption\"])\n",
    "\n",
    "# Deterministic sample of 8\n",
    "n = min(8, len(df))\n",
    "eval_prompts = df.sample(n=n, random_state=42)[\"caption\"].tolist()\n",
    "\n",
    "# Save for reproducibility\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "with open(PROMPT_TXT, \"w\", encoding=\"utf-8\") as f:\n",
    "    for p in eval_prompts:\n",
    "        f.write(p + \"\\n\")\n",
    "\n",
    "print(\"Saved eval prompts ->\", PROMPT_TXT)\n",
    "for i, p in enumerate(eval_prompts, 1):\n",
    "    print(f\"{i:02d}. {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66db60c-4a51-4bca-a61d-1f3a299bb6e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb4e0af97924333b67af1ba4801a8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already available -> diffusers: 0.30.0 | transformers: 4.45.0 | torch: 2.9.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess, os\n",
    "\n",
    "def ensure_diffusers_stack():\n",
    "    \"\"\"\n",
    "    Ensure diffusers + accelerate + transformers + safetensors are available.\n",
    "    If import fails, install into a scratch-local site-packages and append to sys.path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import diffusers, transformers\n",
    "        import torch\n",
    "        print(\"Already available -> diffusers:\", diffusers.__version__,\n",
    "              \"| transformers:\", transformers.__version__,\n",
    "              \"| torch:\", torch.__version__)\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(\"Import failed, will install to scratch site-packages:\", e)\n",
    "\n",
    "    target = \"/scratch/qin.yife/Generative_Project/.python_pkgs\"\n",
    "    os.makedirs(target, exist_ok=True)\n",
    "    print(\"Installing into:\", target)\n",
    "\n",
    "    # Install pinned versions compatible with your current setup\n",
    "    cmd = [\n",
    "        sys.executable, \"-m\", \"pip\", \"install\",\n",
    "        \"--target\", target,\n",
    "        \"diffusers==0.30.0\", \"accelerate==0.34.2\",\n",
    "        \"transformers==4.45.0\", \"safetensors\"\n",
    "    ]\n",
    "    print(\">>\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "    if target not in sys.path:\n",
    "        sys.path.append(target)\n",
    "\n",
    "    import diffusers, transformers, torch\n",
    "    print(\"Installed -> diffusers:\", diffusers.__version__,\n",
    "          \"| transformers:\", transformers.__version__,\n",
    "          \"| torch:\", torch.__version__)\n",
    "\n",
    "ensure_diffusers_stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e4786ec-0b42-4005-8602-6359a952a68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading primary model: runwayml/stable-diffusion-v1-5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd533e26b5ba4537b49a7cecaabeae33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model_index.json:   0%|          | 0.00/541 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73c37641169a4164b73d1ead554d5e36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f348dfb7016483882198bc621dba663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/342 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b275a98f5ea4e7ba539e25a509d57cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfdad9dcfb114d08bc8f602df837b882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea985ba831cb47bfb16641e5c766e6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "scheduler_config.json:   0%|          | 0.00/308 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e49c3c366e9542c895c2a5bd6d9698bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "safety_checker/model.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b22d3df8e5c4ca984043a7efbeb27b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93632288c5b74670ad52e483b5070bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/806 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b655e34465654ce0b02d22e5de80e3b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ea02078bbea4c54941421ea40b365a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/617 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c51675a4ef4105960cee3ff3ad1578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "text_encoder/model.safetensors:   0%|          | 0.00/492M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b193b49b5747438205c608dae161aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unet/diffusion_pytorch_model.safetensors:   0%|          | 0.00/3.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f35e64c9ff45d58afbc1ea77b7f1c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2c4272eba9426a908d0b44f07c50e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/547 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3dd3a3a92c4f46a0821394e3975ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vae/diffusion_pytorch_model.safetensors:   0%|          | 0.00/335M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cb6ab759064ec0a2958ec9ab6e7d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qin.yife/.local/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: runwayml/stable-diffusion-v1-5\n",
      "Scheduler   : DDIMScheduler\n",
      "Device/dtype: cpu / torch.float32\n",
      "Text encoder: CLIPTextModel\n",
      "Tokenizer   : CLIPTokenizer\n",
      "Saved model choice -> /scratch/qin.yife/Generative_Project/outputs/m2/model_choice.json\n"
     ]
    }
   ],
   "source": [
    "import os, json, torch\n",
    "from pathlib import Path\n",
    "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
    "\n",
    "# Paths\n",
    "PROJECT  = Path(\"/scratch/qin.yife/Generative_Project\")\n",
    "OUT_DIR  = PROJECT / \"outputs\" / \"m2\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_META = OUT_DIR / \"model_choice.json\"\n",
    "\n",
    "# Device & dtype\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dtype  = torch.float16 if device == \"cuda\" else torch.float32\n",
    "\n",
    "# Preferred -> SD 1.5 (more scheduler options); Fallback -> SD Turbo (faster on CPU)\n",
    "primary_model   = \"runwayml/stable-diffusion-v1-5\"\n",
    "fallback_model  = \"stabilityai/sd-turbo\"\n",
    "\n",
    "def load_pipe(model_id: str):\n",
    "    pipe = StableDiffusionPipeline.from_pretrained(\n",
    "        model_id,\n",
    "        torch_dtype=dtype,\n",
    "        cache_dir=os.environ.get(\"HF_HOME\"),\n",
    "        use_safetensors=True,\n",
    "    )\n",
    "    # Use DDIM to start (we'll compare schedulers later)\n",
    "    pipe.scheduler = DDIMScheduler.from_config(pipe.scheduler.config)\n",
    "    # Memory-friendly options\n",
    "    try:\n",
    "        pipe.enable_attention_slicing()\n",
    "    except Exception:\n",
    "        pass\n",
    "    pipe = pipe.to(device)\n",
    "    return pipe\n",
    "\n",
    "pipe = None\n",
    "used_model = None\n",
    "try:\n",
    "    print(f\"Loading primary model: {primary_model}\")\n",
    "    pipe = load_pipe(primary_model)\n",
    "    used_model = primary_model\n",
    "except Exception as e:\n",
    "    print(f\"[Warn] Failed to load {primary_model}: {e}\")\n",
    "    print(f\"Falling back to: {fallback_model}\")\n",
    "    pipe = load_pipe(fallback_model)\n",
    "    used_model = fallback_model\n",
    "\n",
    "# Save model choice for reproducibility\n",
    "with open(MODEL_META, \"w\") as f:\n",
    "    json.dump({\"used_model\": used_model, \"device\": device, \"dtype\": str(dtype), \"scheduler\": type(pipe.scheduler).__name__}, f, indent=2)\n",
    "\n",
    "print(\"Loaded model:\", used_model)\n",
    "print(\"Scheduler   :\", type(pipe.scheduler).__name__)\n",
    "print(\"Device/dtype:\", device, \"/\", dtype)\n",
    "print(\"Text encoder:\", pipe.text_encoder.__class__.__name__)\n",
    "print(\"Tokenizer   :\", getattr(pipe, 'tokenizer', None).__class__.__name__)\n",
    "print(\"Saved model choice ->\", MODEL_META)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6bdd2a8-2a6a-4171-b11d-93bbaae609ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa84af967954bce8cbb62422e405556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03c174e3b6d04118aa60b54373b2707b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d1af09e7bb4425e8d0e95200fd5f612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238f4060e9e940c3a10bc2a24dbcdf68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4 images to: /scratch/qin.yife/Generative_Project/outputs/m2\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/baseline_ddim_cfg7.5_s15_seed20251114_01.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/baseline_ddim_cfg7.5_s15_seed20251114_02.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/baseline_ddim_cfg7.5_s15_seed20251114_03.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/baseline_ddim_cfg7.5_s15_seed20251114_04.png\n",
      "Logged to: /scratch/qin.yife/Generative_Project/metrics/m2_runs.csv\n"
     ]
    }
   ],
   "source": [
    "import torch, csv, json\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "PROJECT   = Path(\"/scratch/qin.yife/Generative_Project\")\n",
    "OUT_DIR   = PROJECT / \"outputs\" / \"m2\"\n",
    "LOG_CSV   = PROJECT / \"metrics\" / \"m2_runs.csv\"\n",
    "PROMPT_TXT= OUT_DIR / \"eval_prompts.txt\"\n",
    "MODEL_META= OUT_DIR / \"model_choice.json\"\n",
    "\n",
    "# Load eval prompts (use first 4 for a quick CPU baseline)\n",
    "with open(PROMPT_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    eval_prompts = [ln.strip() for ln in f if ln.strip()]\n",
    "prompts = eval_prompts[:4]\n",
    "\n",
    "# Read model choice (for logging)\n",
    "try:\n",
    "    used_model = json.loads(MODEL_META.read_text())[\"used_model\"]\n",
    "except Exception:\n",
    "    used_model = \"unknown\"\n",
    "\n",
    "# Inference params\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cfg    = 7.5\n",
    "steps  = 15   # keep modest on CPU\n",
    "seed   = 20251114\n",
    "gen    = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "# Generate & save\n",
    "rows = []\n",
    "for i, p in enumerate(prompts, 1):\n",
    "    image = pipe(\n",
    "        p,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=cfg,\n",
    "        generator=gen\n",
    "    ).images[0]\n",
    "    fn = OUT_DIR / f\"baseline_ddim_cfg{cfg}_s{steps}_seed{seed}_{i:02d}.png\"\n",
    "    image.save(fn)\n",
    "\n",
    "    rows.append(dict(\n",
    "        file=str(fn),\n",
    "        prompt=p,\n",
    "        scheduler=type(pipe.scheduler).__name__,\n",
    "        guidance_scale=cfg,\n",
    "        steps=steps,\n",
    "        seed=seed,\n",
    "        model=used_model\n",
    "    ))\n",
    "\n",
    "# Append to CSV log\n",
    "write_header = not LOG_CSV.exists()\n",
    "with open(LOG_CSV, \"a\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Saved {len(rows)} images to:\", OUT_DIR)\n",
    "for r in rows:\n",
    "    print(\" -\", r[\"file\"])\n",
    "print(\"Logged to:\", LOG_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5867004d-dfb2-4904-b864-cd892a21e5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt_embeds: (4, 77, 768) | negative_embeds: (4, 77, 768)\n",
      "scheduler: DDIMScheduler | model: runwayml/stable-diffusion-v1-5 | device: cpu\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f69442b2a114c55a5f83b21e72b0170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7b2530840ea4a12b88d3849e43b7fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41362e5ea94c49e5948a3398d804a595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa971a1542a48ae88ba077ea44b4c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 4 images via prompt_embeds (fixed) to: /scratch/qin.yife/Generative_Project/outputs/m2\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/embedfix_ddim_cfg7.5_s15_seed20251114_01.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/embedfix_ddim_cfg7.5_s15_seed20251114_02.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/embedfix_ddim_cfg7.5_s15_seed20251114_03.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/embedfix_ddim_cfg7.5_s15_seed20251114_04.png\n",
      "Logged to: /scratch/qin.yife/Generative_Project/metrics/m2_runs.csv\n"
     ]
    }
   ],
   "source": [
    "import torch, csv, json\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "PROJECT    = Path(\"/scratch/qin.yife/Generative_Project\")\n",
    "OUT_DIR    = PROJECT / \"outputs\" / \"m2\"\n",
    "LOG_CSV    = PROJECT / \"metrics\" / \"m2_runs.csv\"\n",
    "PROMPT_TXT = OUT_DIR / \"eval_prompts.txt\"\n",
    "MODEL_META = OUT_DIR / \"model_choice.json\"\n",
    "\n",
    "# Load prompts (first 4 to keep CPU runtime reasonable)\n",
    "with open(PROMPT_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    eval_prompts = [ln.strip() for ln in f if ln.strip()]\n",
    "prompts = eval_prompts[:4]\n",
    "\n",
    "# Read model choice (for logging)\n",
    "try:\n",
    "    used_model = json.loads(MODEL_META.read_text())[\"used_model\"]\n",
    "except Exception:\n",
    "    used_model = \"unknown\"\n",
    "\n",
    "# Device / inference params\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "cfg, steps, seed = 7.5, 15, 20251114\n",
    "generator = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "# --- FIXED: encode with padding=\"max_length\" on both pos & neg ---\n",
    "def get_text_and_negative_embeds(texts):\n",
    "    max_len = pipe.tokenizer.model_max_length\n",
    "\n",
    "    # Positive prompts\n",
    "    tok = pipe.tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        pos = pipe.text_encoder(**tok).last_hidden_state  # [B, max_len, 768]\n",
    "\n",
    "    # Negative prompts (empty), same padding/max_length\n",
    "    neg_tok = pipe.tokenizer(\n",
    "        [\"\"] * len(texts),\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_len,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        neg = pipe.text_encoder(**neg_tok).last_hidden_state  # [B, max_len, 768]\n",
    "\n",
    "    return pos, neg\n",
    "\n",
    "prompt_embeds, negative_embeds = get_text_and_negative_embeds(prompts)\n",
    "print(\"prompt_embeds:\", tuple(prompt_embeds.shape), \"| negative_embeds:\", tuple(negative_embeds.shape))\n",
    "print(\"scheduler:\", type(pipe.scheduler).__name__, \"| model:\", used_model, \"| device:\", device)\n",
    "\n",
    "# --- Generate using precomputed embeddings (fixed shapes) ---\n",
    "rows = []\n",
    "for i in range(len(prompts)):\n",
    "    pe = prompt_embeds[i:i+1]\n",
    "    ne = negative_embeds[i:i+1]\n",
    "    image = pipe(\n",
    "        prompt_embeds=pe,\n",
    "        negative_prompt_embeds=ne,\n",
    "        num_inference_steps=steps,\n",
    "        guidance_scale=cfg,\n",
    "        generator=generator,\n",
    "    ).images[0]\n",
    "\n",
    "    fn = OUT_DIR / f\"embedfix_ddim_cfg{cfg}_s{steps}_seed{seed}_{i+1:02d}.png\"\n",
    "    image.save(fn)\n",
    "\n",
    "    rows.append(dict(\n",
    "        file=str(fn),\n",
    "        prompt=prompts[i],\n",
    "        scheduler=type(pipe.scheduler).__name__,\n",
    "        guidance_scale=cfg,\n",
    "        steps=steps,\n",
    "        seed=seed,\n",
    "        via=\"prompt_embeds_maxlen\",\n",
    "        model=used_model,\n",
    "    ))\n",
    "\n",
    "# Append to CSV log\n",
    "write_header = not LOG_CSV.exists()\n",
    "with open(LOG_CSV, \"a\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Saved {len(rows)} images via prompt_embeds (fixed) to:\", OUT_DIR)\n",
    "for r in rows:\n",
    "    print(\" -\", r[\"file\"])\n",
    "print(\"Logged to:\", LOG_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a4e2db0-9af3-4652-a0bf-b330aa2ed454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98477d21ba5d47a1939b568a06245fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98b5858b1d604aeca3e3a5f9c015cf20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41b199bca27f4db18bf98523c144ea57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f696f0cb6f4cee9b8a757a13bcfea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bb4cdbb3664114a4dd67ec447c3d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "003144a5d4f14518ac508d718c121a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f06331fb312f4a989e09143f883625da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b2cae3384c4f77aac2d3fb7ca75325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783633d471404101afb4cede7c7500f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8132f31f3bde4887a1347015f967fd45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7d039569ab4f65a2eeb1c21d09aeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9cd3438ee445dbb017ea25b4b4ec2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc1829c961ad423681f3be60ca509527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7488373663054792929740b110e16b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c7ab551e7040eea483b1380958f47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 15 images to: /scratch/qin.yife/Generative_Project/outputs/m2\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/ddim_CFG3.0_s15_seed20251114_01.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/ddim_CFG3.0_s15_seed20251114_02.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/ddim_CFG3.0_s15_seed20251114_03.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/ddim_CFG5.0_s15_seed20251114_01.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/ddim_CFG5.0_s15_seed20251114_02.png\n",
      "... (truncated)\n",
      "Logged to: /scratch/qin.yife/Generative_Project/metrics/m2_runs.csv\n"
     ]
    }
   ],
   "source": [
    "import torch, csv, json\n",
    "from pathlib import Path\n",
    "\n",
    "# Paths\n",
    "PROJECT    = Path(\"/scratch/qin.yife/Generative_Project\")\n",
    "OUT_DIR    = PROJECT / \"outputs\" / \"m2\"\n",
    "LOG_CSV    = PROJECT / \"metrics\" / \"m2_runs.csv\"\n",
    "PROMPT_TXT = OUT_DIR / \"eval_prompts.txt\"\n",
    "MODEL_META = OUT_DIR / \"model_choice.json\"\n",
    "\n",
    "# Load prompts (use first 3 to keep CPU time reasonable)\n",
    "with open(PROMPT_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    eval_prompts = [ln.strip() for ln in f if ln.strip()]\n",
    "prompts = eval_prompts[:3]\n",
    "\n",
    "# Read model choice (for logging)\n",
    "try:\n",
    "    used_model = json.loads(MODEL_META.read_text())[\"used_model\"]\n",
    "except Exception:\n",
    "    used_model = \"unknown\"\n",
    "\n",
    "# Sweep settings\n",
    "cfg_list = [3.0, 5.0, 7.5, 10.0, 12.0]\n",
    "steps    = 15\n",
    "seed     = 20251114\n",
    "device   = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "rows = []\n",
    "for cfg in cfg_list:\n",
    "    for i, p in enumerate(prompts, 1):\n",
    "        # Recreate generator each call to keep initial noise identical across CFG values\n",
    "        gen = torch.Generator(device=device).manual_seed(seed)\n",
    "\n",
    "        image = pipe(\n",
    "            p,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=cfg,\n",
    "            generator=gen\n",
    "        ).images[0]\n",
    "\n",
    "        fn = OUT_DIR / f\"ddim_CFG{cfg}_s{steps}_seed{seed}_{i:02d}.png\"\n",
    "        image.save(fn)\n",
    "\n",
    "        rows.append(dict(\n",
    "            file=str(fn),\n",
    "            prompt=p,\n",
    "            scheduler=type(pipe.scheduler).__name__,\n",
    "            guidance_scale=cfg,\n",
    "            steps=steps,\n",
    "            seed=seed,\n",
    "            model=used_model,\n",
    "            sweep=\"cfg\"\n",
    "        ))\n",
    "\n",
    "# Append to CSV log\n",
    "write_header = not LOG_CSV.exists()\n",
    "with open(LOG_CSV, \"a\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "    if write_header:\n",
    "        writer.writeheader()\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(f\"Saved {len(rows)} images to:\", OUT_DIR)\n",
    "for r in rows[:5]:\n",
    "    print(\" -\", r[\"file\"])\n",
    "print(\"... (truncated)\")\n",
    "print(\"Logged to:\", LOG_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0e69733-12be-4e80-b7fe-4adbe9bc83a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48220a7bb541489192a2b2f8d58f2943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f946887198948418af42bcdacb406e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "318157f407bc468c8d4cdfa5a8160296",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7a66fe70b6c4a22a44a483c79c201c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267c4a57ff764f538f8752a6897a7d44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2435740cfc4ca1944f51e1bdaad753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 6 images across schedulers to: /scratch/qin.yife/Generative_Project/outputs/m2\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/DDIM_CFG7.5_s15_seed20251114_01.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/DDIM_CFG7.5_s15_seed20251114_02.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/EulerA_CFG7.5_s15_seed20251114_01.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/EulerA_CFG7.5_s15_seed20251114_02.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/DPMSolver_CFG7.5_s15_seed20251114_01.png\n",
      " - /scratch/qin.yife/Generative_Project/outputs/m2/DPMSolver_CFG7.5_s15_seed20251114_02.png\n",
      "Logged to: /scratch/qin.yife/Generative_Project/metrics/m2_runs.csv\n"
     ]
    }
   ],
   "source": [
    "import torch, csv, json, os\n",
    "from pathlib import Path\n",
    "from diffusers import DDIMScheduler, EulerAncestralDiscreteScheduler, DPMSolverMultistepScheduler\n",
    "\n",
    "# Paths\n",
    "PROJECT    = Path(\"/scratch/qin.yife/Generative_Project\")\n",
    "OUT_DIR    = PROJECT / \"outputs\" / \"m2\"; OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "LOG_CSV    = PROJECT / \"metrics\" / \"m2_runs.csv\"\n",
    "PROMPT_TXT = OUT_DIR / \"eval_prompts.txt\"\n",
    "MODEL_META = OUT_DIR / \"model_choice.json\"\n",
    "\n",
    "# Load prompts (first 2 to keep CPU runtime reasonable)\n",
    "with open(PROMPT_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    eval_prompts = [ln.strip() for ln in f if ln.strip()]\n",
    "prompts = eval_prompts[:2]\n",
    "\n",
    "# Read model choice (for logging)\n",
    "try:\n",
    "    used_model = json.loads(MODEL_META.read_text())[\"used_model\"]\n",
    "except Exception:\n",
    "    used_model = \"unknown\"\n",
    "\n",
    "# Settings\n",
    "steps = 15\n",
    "cfg   = 7.5\n",
    "seed  = 20251114\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "def run_with_scheduler(sched_cls, tag: str):\n",
    "    # Switch scheduler\n",
    "    pipe.scheduler = sched_cls.from_config(pipe.scheduler.config)\n",
    "    rows = []\n",
    "    for i, p in enumerate(prompts, 1):\n",
    "        gen = torch.Generator(device=device).manual_seed(seed)  # fixed noise for fair comparison\n",
    "        image = pipe(\n",
    "            p, num_inference_steps=steps, guidance_scale=cfg, generator=gen\n",
    "        ).images[0]\n",
    "        fn = OUT_DIR / f\"{tag}_CFG{cfg}_s{steps}_seed{seed}_{i:02d}.png\"\n",
    "        image.save(fn)\n",
    "        rows.append(dict(\n",
    "            file=str(fn),\n",
    "            prompt=p,\n",
    "            scheduler=type(pipe.scheduler).__name__,\n",
    "            guidance_scale=cfg,\n",
    "            steps=steps,\n",
    "            seed=seed,\n",
    "            model=used_model,\n",
    "            sweep=\"scheduler\"\n",
    "        ))\n",
    "    return rows\n",
    "\n",
    "rows = []\n",
    "rows += run_with_scheduler(DDIMScheduler,                   \"DDIM\")\n",
    "rows += run_with_scheduler(EulerAncestralDiscreteScheduler, \"EulerA\")\n",
    "rows += run_with_scheduler(DPMSolverMultistepScheduler,     \"DPMSolver\")\n",
    "\n",
    "# Append to CSV log\n",
    "write_header = not LOG_CSV.exists()\n",
    "with open(LOG_CSV, \"a\", newline=\"\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=list(rows[0].keys()))\n",
    "    if write_header: w.writeheader()\n",
    "    w.writerows(rows)\n",
    "\n",
    "print(f\"Saved {len(rows)} images across schedulers to:\", OUT_DIR)\n",
    "for r in rows:\n",
    "    print(\" -\", r[\"file\"])\n",
    "print(\"Logged to:\", LOG_CSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa0ad2bc-a193-44fb-9247-4f92fc28a582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 10 images (most recent) for submission.\n",
      "Copied to: /scratch/qin.yife/Generative_Project/outputs/m2/submit\n",
      " - m2_01.png <- DPMSolver_CFG7.5_s15_seed20251114_02.png\n",
      " - m2_02.png <- DPMSolver_CFG7.5_s15_seed20251114_01.png\n",
      " - m2_03.png <- EulerA_CFG7.5_s15_seed20251114_02.png\n",
      " - m2_04.png <- EulerA_CFG7.5_s15_seed20251114_01.png\n",
      " - m2_05.png <- DDIM_CFG7.5_s15_seed20251114_02.png\n",
      " ...\n",
      "Wrote manifest -> /scratch/qin.yife/Generative_Project/outputs/m2/submit/manifest.csv\n",
      "Wrote 1-page summary template -> /scratch/qin.yife/Generative_Project/outputs/m2/M2_summary_template.md\n",
      "SUBMIT folder ready: /scratch/qin.yife/Generative_Project/outputs/m2/submit\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil, csv, json\n",
    "\n",
    "# Paths\n",
    "PROJECT    = Path(\"/scratch/qin.yife/Generative_Project\")\n",
    "OUT_DIR    = PROJECT / \"outputs\" / \"m2\"\n",
    "SUBMIT_DIR = OUT_DIR / \"submit\"\n",
    "LOG_CSV    = PROJECT / \"metrics\" / \"m2_runs.csv\"\n",
    "MODEL_META = OUT_DIR / \"model_choice.json\"\n",
    "SUMMARY_MD = OUT_DIR / \"M2_summary_template.md\"\n",
    "\n",
    "SUBMIT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 1) Pick up to 10 most recent PNGs (ensure at least 5 if possible)\n",
    "pngs = sorted([p for p in OUT_DIR.glob(\"*.png\")], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "if not pngs:\n",
    "    raise RuntimeError(\"No PNG files found in OUT_DIR.\")\n",
    "selected = pngs[:10] if len(pngs) >= 10 else pngs\n",
    "print(f\"Selected {len(selected)} images (most recent) for submission.\")\n",
    "\n",
    "# 2) Copy into SUBMIT_DIR with ordered names m2_01.png, m2_02.png, ...\n",
    "copied = []\n",
    "for i, src in enumerate(selected, 1):\n",
    "    dst = SUBMIT_DIR / f\"m2_{i:02d}.png\"\n",
    "    shutil.copy2(src, dst)\n",
    "    copied.append((src, dst))\n",
    "print(\"Copied to:\", SUBMIT_DIR)\n",
    "for src, dst in copied[:5]:\n",
    "    print(\" -\", dst.name, \"<-\", src.name)\n",
    "if len(copied) > 5:\n",
    "    print(\" ...\")\n",
    "\n",
    "# 3) Robustly read log CSV (tolerate inconsistent columns)\n",
    "def load_log_rows(path: Path):\n",
    "    rows = []\n",
    "    if not path.exists():\n",
    "        return rows\n",
    "    with open(path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f, restkey=\"__extra__\", restval=\"\")\n",
    "        for r in reader:\n",
    "            rows.append(r)\n",
    "    return rows\n",
    "\n",
    "log_rows = load_log_rows(LOG_CSV)\n",
    "index_by_basename = {}\n",
    "for r in log_rows:\n",
    "    fpath = (r.get(\"file\") or \"\").strip()\n",
    "    if fpath:\n",
    "        index_by_basename[Path(fpath).name] = r\n",
    "\n",
    "# 4) Build manifest with normalized columns\n",
    "manifest_cols = [\"submit_name\",\"file\",\"prompt\",\"scheduler\",\"guidance_scale\",\"steps\",\"seed\",\"model\"]\n",
    "manifest_path = SUBMIT_DIR / \"manifest.csv\"\n",
    "with open(manifest_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    w = csv.DictWriter(f, fieldnames=manifest_cols)\n",
    "    w.writeheader()\n",
    "    for src, dst in copied:\n",
    "        r = index_by_basename.get(src.name, {})\n",
    "        row = {\n",
    "            \"submit_name\": dst.name,\n",
    "            \"file\": r.get(\"file\", str(src)),\n",
    "            \"prompt\": r.get(\"prompt\", \"\"),\n",
    "            \"scheduler\": r.get(\"scheduler\", \"\"),\n",
    "            \"guidance_scale\": r.get(\"guidance_scale\", \"\"),\n",
    "            \"steps\": r.get(\"steps\", \"\"),\n",
    "            \"seed\": r.get(\"seed\", \"\"),\n",
    "            \"model\": r.get(\"model\", \"\"),\n",
    "        }\n",
    "        w.writerow(row)\n",
    "print(\"Wrote manifest ->\", manifest_path)\n",
    "\n",
    "# 5) 1-page summary template (fill basics; you add observations)\n",
    "used_model = \"unknown\"; device=\"cpu\"; dtype=\"torch.float32\"; scheduler=\"(varies)\"\n",
    "try:\n",
    "    meta = json.loads(MODEL_META.read_text())\n",
    "    used_model = meta.get(\"used_model\", used_model)\n",
    "    device     = meta.get(\"device\", device)\n",
    "    dtype      = meta.get(\"dtype\", dtype)\n",
    "    scheduler  = meta.get(\"scheduler\", scheduler)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Derive distinct values from log (tolerant)\n",
    "cfgs, scheds, steps = set(), set(), set()\n",
    "for r in log_rows:\n",
    "    if r.get(\"guidance_scale\", \"\") != \"\": cfgs.add(str(r[\"guidance_scale\"]))\n",
    "    if r.get(\"scheduler\", \"\") != \"\":      scheds.add(str(r[\"scheduler\"]))\n",
    "    if r.get(\"steps\", \"\") != \"\":          steps.add(str(int(float(r[\"steps\"]))))\n",
    "\n",
    "summary = f\"\"\"# Milestone 2 — Summary (Template)\n",
    "\n",
    "**Dataset**: Flickr30k (cleaned 5k pairs) → `data/processed/pairs.clean.csv`  \n",
    "**Model**: {used_model}  \n",
    "**Device / dtype**: {device} / {dtype}  \n",
    "**Schedulers tested**: {\", \".join(sorted(scheds)) if scheds else scheduler}  \n",
    "**Guidance scales tested (CFG)**: {\", \".join(sorted(cfgs)) if cfgs else \"N/A\"}  \n",
    "**Steps tested**: {\", \".join(sorted(steps)) if steps else \"15\"}  \n",
    "**Early samples**: {len(selected)} images in `outputs/m2/submit/` (see `manifest.csv`)\n",
    "\n",
    "## What we did\n",
    "- Integrated CLIP text encoder with diffusion pipeline (`prompt_embeds` + `negative_prompt_embeds`).\n",
    "- Baseline conditional generation (DDIM), CFG sweep, and scheduler comparison (DDIM / Euler-A / DPM-Solver).\n",
    "- Logged runs to `metrics/m2_runs.csv`.\n",
    "\n",
    "## Observations (fill in briefly)\n",
    "- **CFG**: _low CFG → more diversity but weaker adherence; high CFG → better alignment but risk of artifacts/collapse._\n",
    "- **Schedulers**: _Euler-A often sharper; DPM-Solver converges faster; DDIM stable but softer at same steps._\n",
    "- **Failure modes**: _e.g., counting objects, text rendering, small details; high CFG may over-saturate._\n",
    "- **Runtime (CPU)**: _kept steps small; fixed seed for fair comparison._\n",
    "\n",
    "## Next (toward M3)\n",
    "- Add quantitative metrics (FID/IS) on GPU; keep CLIPScore as a quick proxy.\n",
    "- Parameter sensitivity grid (CFG × steps × scheduler) to select best trade-offs.\n",
    "- Optional: lightweight LoRA finetune on a subset for better alignment.\n",
    "\"\"\"\n",
    "SUMMARY_MD.write_text(summary, encoding=\"utf-8\")\n",
    "print(\"Wrote 1-page summary template ->\", SUMMARY_MD)\n",
    "print(\"SUBMIT folder ready:\", SUBMIT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9477f08a-a348-423d-a9e7-c527bc8f8685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built comparison panels.\n",
      "Folders written under: /scratch/qin.yife/Generative_Project/outputs/m2/compare_by_prompt\n",
      "Global panel manifest -> /scratch/qin.yife/Generative_Project/outputs/m2/compare_by_prompt/panel_manifest.csv\n",
      "Markdown gallery -> /scratch/qin.yife/Generative_Project/outputs/m2/compare_by_prompt/gallery.md\n",
      "Prompts grouped: 4 (capped 18 images per prompt)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import csv, re, shutil, math\n",
    "\n",
    "# ---------- paths ----------\n",
    "PROJECT     = Path(\"/scratch/qin.yife/Generative_Project\")\n",
    "M2_OUT_DIR  = PROJECT / \"outputs\" / \"m2\"\n",
    "LOG_CSV     = PROJECT / \"metrics\" / \"m2_runs.csv\"\n",
    "COMPARE_DIR = M2_OUT_DIR / \"compare_by_prompt\"\n",
    "COMPARE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "GALLERY_MD  = COMPARE_DIR / \"gallery.md\"\n",
    "PANEL_CSV   = COMPARE_DIR / \"panel_manifest.csv\"\n",
    "\n",
    "# ---------- robust log reader (tolerate inconsistent columns) ----------\n",
    "def load_log_rows(path: Path):\n",
    "    rows = []\n",
    "    if not path.exists():\n",
    "        return rows\n",
    "    with open(path, \"r\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        reader = csv.DictReader(f, restkey=\"__extra__\", restval=\"\")\n",
    "        for r in reader:\n",
    "            # normalize some fields\n",
    "            r[\"file\"] = (r.get(\"file\") or \"\").strip()\n",
    "            r[\"prompt\"] = (r.get(\"prompt\") or \"\").strip()\n",
    "            r[\"scheduler\"] = (r.get(\"scheduler\") or \"\").strip()\n",
    "            r[\"guidance_scale\"] = (r.get(\"guidance_scale\") or \"\").strip()\n",
    "            r[\"steps\"] = (r.get(\"steps\") or \"\").strip()\n",
    "            r[\"seed\"] = (r.get(\"seed\") or \"\").strip()\n",
    "            r[\"via\"]  = (r.get(\"via\")  or \"\").strip()\n",
    "            r[\"tag\"]  = (r.get(\"tag\")  or \"\").strip()\n",
    "            rows.append(r)\n",
    "    return rows\n",
    "\n",
    "log_rows = load_log_rows(LOG_CSV)\n",
    "\n",
    "# ---------- index by prompt ----------\n",
    "# keep only rows that actually have an existing image file\n",
    "valid = []\n",
    "for r in log_rows:\n",
    "    fp = Path(r[\"file\"])\n",
    "    if fp.suffix.lower() in {\".png\", \".jpg\", \".jpeg\"} and fp.exists():\n",
    "        valid.append(r)\n",
    "\n",
    "# group by prompt text\n",
    "from collections import defaultdict\n",
    "by_prompt = defaultdict(list)\n",
    "for r in valid:\n",
    "    if r[\"prompt\"]:\n",
    "        by_prompt[r[\"prompt\"]].append(r)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def slugify(text: str, max_len: int = 64):\n",
    "    # keep letters/numbers/space, collapse whitespace, hyphenate\n",
    "    t = re.sub(r\"[^A-Za-z0-9\\s\\-]+\", \"\", text).strip()\n",
    "    t = re.sub(r\"\\s+\", \" \", t)\n",
    "    slug = t.lower().replace(\" \", \"-\")\n",
    "    if len(slug) > max_len:\n",
    "        slug = slug[:max_len].rstrip(\"-\")\n",
    "    return slug if slug else \"prompt\"\n",
    "\n",
    "def label_from_row(r: dict):\n",
    "    # human-readable parameter label for filenames and captions\n",
    "    sch = r[\"scheduler\"] or \"?\"\n",
    "    cfg = r[\"guidance_scale\"] or \"?\"\n",
    "    stp = r[\"steps\"] or \"?\"\n",
    "    via = r[\"via\"] or \"\"\n",
    "    tag = r[\"tag\"] or \"\"\n",
    "    extra = []\n",
    "    if via: extra.append(via)\n",
    "    if tag: extra.append(tag)\n",
    "    extra_str = (\"-\" + \"-\".join(extra)) if extra else \"\"\n",
    "    return f\"{sch}_cfg{cfg}_s{stp}{extra_str}\"\n",
    "\n",
    "# ---------- build panels ----------\n",
    "# limit per prompt to avoid huge folders (you can change this later)\n",
    "MAX_PER_PROMPT = 18\n",
    "\n",
    "panel_rows = []   # for global CSV\n",
    "sections = []     # for gallery.md\n",
    "\n",
    "prompt_ids = sorted(by_prompt.keys())\n",
    "if not prompt_ids:\n",
    "    raise RuntimeError(\"No valid (prompt, image) pairs found from the log. Make sure you ran M2 cells and logged runs.\")\n",
    "\n",
    "for idx, prompt in enumerate(prompt_ids, start=1):\n",
    "    items = by_prompt[prompt]\n",
    "    # sort by (scheduler, numeric cfg, steps, filename) for stable panels\n",
    "    def to_float(x):\n",
    "        try: return float(x)\n",
    "        except: return math.inf\n",
    "    items.sort(key=lambda r: (r[\"scheduler\"], to_float(r[\"guidance_scale\"]), to_float(r[\"steps\"]), r[\"file\"]))\n",
    "\n",
    "    # cap to MAX_PER_PROMPT (keeps panels compact for the report)\n",
    "    items = items[:MAX_PER_PROMPT]\n",
    "\n",
    "    slug = f\"p{idx:02d}_\" + slugify(prompt, max_len=48)\n",
    "    pdir = COMPARE_DIR / slug\n",
    "    pdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # copy images into the prompt folder with labeled names\n",
    "    copied = []\n",
    "    for j, r in enumerate(items, start=1):\n",
    "        src = Path(r[\"file\"])\n",
    "        label = label_from_row(r)\n",
    "        dst = pdir / f\"{j:02d}_{label}{src.suffix.lower()}\"\n",
    "        shutil.copy2(src, dst)\n",
    "        copied.append((src, dst, r))\n",
    "\n",
    "        # collect for global CSV\n",
    "        panel_rows.append({\n",
    "            \"prompt_id\": f\"{idx:02d}\",\n",
    "            \"prompt\": prompt,\n",
    "            \"prompt_slug\": slug,\n",
    "            \"dst_name\": dst.name,\n",
    "            \"src_path\": str(src),\n",
    "            \"scheduler\": r[\"scheduler\"],\n",
    "            \"guidance_scale\": r[\"guidance_scale\"],\n",
    "            \"steps\": r[\"steps\"],\n",
    "            \"seed\": r[\"seed\"],\n",
    "            \"via\": r[\"via\"],\n",
    "            \"tag\": r[\"tag\"],\n",
    "        })\n",
    "\n",
    "    # build markdown section for this prompt\n",
    "    sections.append(f\"## {idx:02d}. {prompt}\\n\\n**Folder:** `{slug}`  \\n\")\n",
    "    if copied:\n",
    "        # make a small gallery table (3 per row)\n",
    "        rows_md = []\n",
    "        row = []\n",
    "        for k, (_, dst, r) in enumerate(copied, start=1):\n",
    "            cap = label_from_row(r)\n",
    "            row.append(f'<div><img src=\"{slug}/{dst.name}\" width=\"260\"><br><sub>{cap}</sub></div>')\n",
    "            if k % 3 == 0:\n",
    "                rows_md.append(\"<p>\" + \" \".join(row) + \"</p>\")\n",
    "                row = []\n",
    "        if row:\n",
    "            rows_md.append(\"<p>\" + \" \".join(row) + \"</p>\")\n",
    "        sections.append(\"\\n\".join(rows_md))\n",
    "    sections.append(\"\\n---\\n\")\n",
    "\n",
    "# write global panel manifest\n",
    "with open(PANEL_CSV, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    cols = [\"prompt_id\",\"prompt\",\"prompt_slug\",\"dst_name\",\"src_path\",\"scheduler\",\"guidance_scale\",\"steps\",\"seed\",\"via\",\"tag\"]\n",
    "    w = csv.DictWriter(f, fieldnames=cols)\n",
    "    w.writeheader()\n",
    "    for r in panel_rows:\n",
    "        w.writerow(r)\n",
    "\n",
    "# write gallery markdown\n",
    "header = (\n",
    "    \"# Milestone 2 — Prompt-wise Comparison Panels\\n\\n\"\n",
    "    f\"- Root: `{COMPARE_DIR}`\\n\"\n",
    "    f\"- Global manifest: `{PANEL_CSV.name}`\\n\"\n",
    "    \"- Each section shows **the same prompt** with **different parameters** (scheduler/CFG/steps), filenames include settings.\\n\\n\"\n",
    "    \"---\\n\"\n",
    ")\n",
    "GALLERY_MD.write_text(header + \"\\n\".join(sections), encoding=\"utf-8\")\n",
    "\n",
    "print(\"Built comparison panels.\")\n",
    "print(\"Folders written under:\", COMPARE_DIR)\n",
    "print(\"Global panel manifest ->\", PANEL_CSV)\n",
    "print(\"Markdown gallery ->\", GALLERY_MD)\n",
    "print(f\"Prompts grouped: {len(prompt_ids)} (capped {MAX_PER_PROMPT} images per prompt)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8c621b-ecc1-4a9a-b3f7-0bdd0fa147f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
